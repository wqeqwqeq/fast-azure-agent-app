---
name: onboard
description: Interactive agent factory onboarding. Use when the user runs /onboard or wants to create multi-agent applications, set up new specialized agents for a domain, or generate sub-agent configurations and tool stubs.
---

# Agent Factory Onboarding Skill

When the user runs `/onboard`, follow this process to create a new agent application configuration.

## Overview

This skill helps users create a multi-agent application by:
1. Interactively collecting application configuration (domain + sub-agents)
2. Generating sub-agent configuration and files
3. **Modifying orchestration agent prompts** based on sub-agent info (LLM-driven, not string parsing)
4. Optionally implementing tool logic

## Architecture

```
/onboard skill collects info
    ↓
Generate subagent_config.py + sub-agent files
    ↓
Modify orchestration agent prompts (Claude fills {placeholders} using LLM reasoning)
    ↓
Done - prompts are customized for this domain
```

---

## Phase 1: Collect Configuration

Ask the user these questions sequentially (wait for each answer before proceeding):

### Step 1: Domain Configuration
Ask: "What domain does this assistant serve? Please provide:
1. **Domain name** (e.g., 'HR Assistant', 'IT Support')
2. **Description** (one sentence explaining what the assistant helps with)"

### Step 2: Sub-Agents
For each sub-agent, collect:
1. **key** (snake_case identifier, e.g., `leave`, `payroll`)
2. **name** (display name, e.g., 'leave-agent')
3. **description** (one-line description)
4. **capabilities** (list of things this agent can do)
5. **tools** (list of tool functions with name and description)
6. **use_cases** (2-3 use cases with example user queries) - NEW
7. **when_to_use** (scenarios where triage should route here) - NEW
8. **when_not_to_use** (scenarios where another agent is better) - NEW

Ask: "Now let's define your specialized agents. For each agent, I need:
- **Key**: Unique identifier (snake_case)
- **Name**: Display name
- **Description**: What this agent handles
- **Capabilities**: List of specific things it can do
- **Tools**: Functions it needs (name + what it does)
- **Use Cases**: 2-3 examples of what users ask, with example queries
- **When to Route Here**: Scenarios where this agent is the right choice
- **When NOT to Route Here**: Scenarios where another agent is better

Please describe your first agent."

Continue asking: "Do you have another agent to add? (yes/no)"

### Step 3: Confirm Configuration
Present a summary of the collected configuration and ask for confirmation:

```
## Configuration Summary

**Domain**: {domain_name} - {domain_description}

**Agents**:
1. **{agent1_key}** ({agent1_name})
   - Description: {description}
   - Capabilities: {capabilities}
   - Tools: {tools}
   - Use Cases: {use_cases with example queries}
   - Route here when: {when_to_use}
   - Do NOT route here when: {when_not_to_use}

2. ...

Does this look correct? (yes/no)
```

---

## Phase 2: Generate Sub-Agent Files

After confirmation, generate:

### 1. `app/agent_factory/subagent_config.py`

```python
"""Sub-Agent Configuration for Agent Factory.

Generated by /onboard skill.
"""

from .schemas.config import SubAgentConfig, ToolConfig, ToolParameterConfig, UseCaseConfig

# Domain configuration
DOMAIN_NAME = "{domain_name}"
DOMAIN_DESCRIPTION = "{domain_description}"

# Sub-agent definitions
SUB_AGENTS: list[SubAgentConfig] = [
    SubAgentConfig(
        key="{agent_key}",
        name="{agent_name}",
        description="{agent_description}",
        capabilities=[
            "{capability_1}",
            "{capability_2}",
        ],
        tools=[
            ToolConfig(
                name="{tool_name}",
                description="{tool_description}",
                parameters=[...],
            ),
        ],
        use_cases=[
            UseCaseConfig(
                intent="{what user wants}",
                example_queries=["{query1}", "{query2}"],
            ),
        ],
        when_to_use=["{scenario1}", "{scenario2}"],
        when_not_to_use=["{anti_scenario1}"],
    ),
    # ... more agents
]
```

### 2. Sub-Agent Files

For each agent, create `app/agent_factory/agents/sub_agents/{key}_agent.py` with enriched prompts (not just basic instructions).

### 3. Tool Stub Files

For each agent, create `app/agent_factory/agents/sub_agents/tools/{key}_tools.py`.

---

## Phase 3: Modify Orchestration Agent Prompts (CRITICAL)

After generating sub-agent files, **modify the orchestration agent prompts** based on the sub-agent information.

### How It Works

Each orchestration agent in `app/agent_factory/agents/orchestration/` has an `instructions` field with `{placeholders}`. Claude should:

1. **Read** each orchestration agent file
2. **Fill `{placeholders}`** using LLM reasoning based on sub-agent configs
3. **Modify any other text** if it improves the prompt for this domain
4. **DO NOT modify** the output format section (it's captured by schema)
5. **Write** the updated prompt back to the file

### Orchestration Agents and Their Placeholders

| Agent | Key Placeholders to Fill |
|-------|--------------------------|
| `triage_agent.py` | `{domain_purpose}`, `{agent_summaries}`, `{routing_examples}`, `{decision_guidelines}` |
| `plan_agent.py` | `{domain_purpose}`, `{agent_tools_summary}`, `{planning_examples}`, `{parallel_vs_sequential_guidance}` |
| `replan_agent.py` | `{agent_tools_summary}`, `{retry_examples}`, `{when_to_retry_vs_complete}` |
| `review_agent.py` | `{completeness_criteria}`, `{domain_specific_quality_checks}`, `{review_examples}` |
| `clarify_agent.py` | `{domain_purpose}`, `{capabilities_summary}`, `{clarification_examples}` |
| `summary_agent.py` | `{domain_purpose}`, `{formatting_guidelines}`, `{response_examples}` |

### Example Transformation

**BEFORE** (template in `triage_agent.py`):
```python
instructions: str = """You are a triage agent for {domain_purpose}...

## Specialized Agents Available:
{agent_summaries}

## Routing Examples:
{routing_examples}
"""
```

**AFTER** (Claude fills for HR domain):
```python
instructions: str = """You are a triage agent for HR Assistant that helps employees manage leave, payroll, and benefits...

## Specialized Agents Available:

### leave (Leave Management Agent)
Handles employee leave requests, PTO balances, and time-off submissions.
- **Tools**: get_leave_balance, submit_leave_request, cancel_leave_request
- **Use for**: "How many vacation days?", "Request time off", "Cancel my leave"
- **Do NOT use for**: Pay during leave (→ payroll), approval status (→ approvals)

### payroll (Payroll Agent)
Handles salary, compensation, and payment queries.
- **Tools**: get_pay_stub, get_bonus_info
- **Use for**: "Show my pay stub", "When is payday?", "Bonus information"
- **Do NOT use for**: Leave balance (→ leave)

## Routing Examples:
- "How many vacation days do I have?" → leave agent
- "Show me my last pay stub" → payroll agent
- "Will I get paid during my vacation?" → This is about PAY, route to payroll
- "Request March 15-22 off" → leave agent
"""
```

### Key Principles

**The template is just a starting point.** Claude should:
1. Fill `{placeholders}` with domain-specific content
2. Modify surrounding text if it improves the prompt
3. Add sections if needed for this domain
4. Remove irrelevant sections
5. **NEVER modify output format** (captured by schema)
6. **ALWAYS write in English** - all prompts must be in English regardless of user's language

---

## Phase 4: Post-Generation Summary

After generating files AND modifying orchestration prompts, tell the user:

```
## Files Generated/Modified

### Generated:
1. `app/agent_factory/subagent_config.py` - Sub-agent configuration
2. `app/agent_factory/agents/sub_agents/{key}_agent.py` - Agent for each sub-agent
3. `app/agent_factory/agents/sub_agents/tools/{key}_tools.py` - Tool stubs

### Modified (prompts customized for your domain):
4. `app/agent_factory/agents/orchestration/triage_agent.py`
5. `app/agent_factory/agents/orchestration/plan_agent.py`
6. `app/agent_factory/agents/orchestration/replan_agent.py`
7. `app/agent_factory/agents/orchestration/review_agent.py`
8. `app/agent_factory/agents/orchestration/clarify_agent.py`
9. `app/agent_factory/agents/orchestration/summary_agent.py`

## Next Steps

1. **Implement Tools**: The tool functions in `tools/{key}_tools.py` are stubs.
2. **Test Your Application**:
   ```bash
   USE_DEMO_OPSAGENT=false uv run uvicorn app.main:app --reload
   ```

Would you like me to help implement any of the tool functions?
```

---

## Phase 5: Tool Implementation (Optional)

If the user wants help implementing tools:

### Step 1: Gather Requirements
Ask for implementation details (API endpoints, business logic, data sources, SDKs to use)

### Step 2: Add Dependencies
Before implementing, add required packages:
```bash
uv add <package-name>
```

Example for Azure tools:
```bash
uv add azure-identity azure-mgmt-storage azure-storage-blob azure-keyvault-secrets azure-mgmt-keyvault
```

### Step 3: Implement Tools
- Replace the `NotImplementedError` stubs with actual code
- Use SDK best practices (check official documentation)
- Keep tools simple - avoid over-parsing SDK responses
- For data plane operations (e.g., list blobs, get secrets), usually only need resource name, NOT resource group

### Step 4: Test Each Tool (CRITICAL)
After implementation, create a test file to verify each tool works:

```python
# test_tools.py (create in project root)
"""Quick test for tool functions."""

import asyncio
from app.agent_factory.agents.sub_agents.tools.{key}_tools import (
    tool_function_1,
    tool_function_2,
)

def test_tool_function_1():
    """Test tool_function_1."""
    result = tool_function_1(param1="test_value")
    print(f"tool_function_1 result:\n{result}\n")
    assert "error" not in result.lower(), f"Tool returned error: {result}"

def test_tool_function_2():
    """Test tool_function_2."""
    result = tool_function_2(param1="test_value", param2="test_value2")
    print(f"tool_function_2 result:\n{result}\n")
    assert "error" not in result.lower(), f"Tool returned error: {result}"

if __name__ == "__main__":
    print("Testing tools...\n")
    test_tool_function_1()
    test_tool_function_2()
    print("All tools passed!")
```

Run the test:
```bash
uv run python test_tools.py
```

### Step 5: Iterate Until All Tools Pass
- If a tool fails, fix the implementation
- Re-run the test
- Repeat until all tools pass
- Delete the test file after verification (or keep for future use)

---

## Important Notes

- Always use snake_case for keys and function names
- Always use PascalCase for class names
- Tool functions must return JSON strings
- Use `Annotated` type hints for parameters
- **Orchestration prompts are filled by Claude (LLM), not Python string parsing**
- **DO NOT modify output format sections** in orchestration agents (captured by schema)
- **ALWAYS write prompts in English** - all orchestration agent prompts and sub-agent instructions must be in English, regardless of the user's language or domain
- Infer parameter types from descriptions when not explicitly provided

---

## Example Session

```
User: /onboard

Claude: What domain does this assistant serve? Please provide:
1. **Domain name** (e.g., 'HR Assistant', 'IT Support')
2. **Description** (one sentence explaining what the assistant helps with)

User: HR Assistant - Helps employees manage leave, check payroll, and access benefits information

Claude: Now let's define your specialized agents. For each agent, I need:
- **Key**: Unique identifier (snake_case)
- **Name**: Display name
- **Description**: What this agent handles
- **Capabilities**: List of specific things it can do
- **Tools**: Functions it needs (name + what it does)
- **Use Cases**: 2-3 examples of what users ask, with example queries
- **When to Route Here**: Scenarios where this agent is the right choice
- **When NOT to Route Here**: Scenarios where another agent is better

Please describe your first agent.

User: leave agent - handles vacation and leave requests
- Capabilities: Check leave balance, Submit leave requests, Cancel leave
- Tools: get_leave_balance, submit_leave_request, cancel_leave_request
- Use cases:
  - Check balance: "How many vacation days?", "What's my PTO?"
  - Request leave: "I need time off next week", "Book March 15-22"
- Route here when: PTO, vacation, sick leave, time off requests
- Don't route here when: questions about PAY during leave (that's payroll)

Claude: Got it! Do you have another agent to add? (yes/no)

User: yes, payroll agent for salary and compensation
- Capabilities: View pay stubs, Check bonus info
- Tools: get_pay_stub, get_bonus_info
- Use cases:
  - Pay stub: "Show my last paycheck", "When do I get paid?"
  - Bonus: "What's my bonus this quarter?"
- Route here when: salary, pay, compensation, bonus questions
- Don't route here when: leave balance (that's leave agent)

Claude: Do you have another agent to add? (yes/no)

User: no

Claude: ## Configuration Summary

**Domain**: HR Assistant - Helps employees manage leave, check payroll, and access benefits information

**Agents**:
1. **leave** (leave-agent)
   - Description: Handles vacation and leave requests
   - Capabilities: Check leave balance, Submit leave requests, Cancel leave
   - Tools: get_leave_balance, submit_leave_request, cancel_leave_request
   - Use Cases: Check balance ("How many vacation days?"), Request leave ("Book March 15-22")
   - Route here when: PTO, vacation, sick leave, time off requests
   - Do NOT route here when: Questions about PAY during leave (→ payroll)

2. **payroll** (payroll-agent)
   - Description: Handles salary and compensation queries
   - Capabilities: View pay stubs, Check bonus info
   - Tools: get_pay_stub, get_bonus_info
   - Use Cases: Pay stub ("Show my last paycheck"), Bonus ("What's my bonus?")
   - Route here when: Salary, pay, compensation, bonus questions
   - Do NOT route here when: Leave balance (→ leave)

Does this look correct? (yes/no)

User: yes

Claude: [Generates sub-agent files...]
Claude: [Modifies orchestration agent prompts with domain-specific content...]

## Files Generated/Modified
...
```
